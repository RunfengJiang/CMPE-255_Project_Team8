{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classificationModels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "# function for building the decision tree\n",
        "# Return: trained decision tree\n",
        "def decision_tree_build(train_data, label_data, criterion, min_samples_split, max_depth):\n",
        "  print(\"BUILDING DECISION TREE ... \")\n",
        "  print(\"Training Data Shape: \" + str(train_data.shape))\n",
        "  dt_clf = DecisionTreeClassifier(criterion = criterion,\n",
        "                                  min_samples_split = min_samples_split,\n",
        "                                  max_depth = max_depth)\n",
        "  dt_clf.fit(train_data, label_data)\n",
        "  return dt_clf\n",
        "\n",
        "# function for building the random forest\n",
        "# Return: trained random forest classifier\n",
        "def random_forest_build(train_data, label_data, criterion, n_estimators):\n",
        "  print(\"BUILDING RANDOM FOREST ... \")\n",
        "  print(\"Training Data Shape: \" + str(train_data.shape))\n",
        "  rf_clf = RandomForestClassifier(n_estimators = n_estimators,\n",
        "                                  criterion = criterion)\n",
        "  rf_clf.fit(train_data, label_data)\n",
        "  return rf_clf\n",
        "\n",
        "# prediction function for the given data and classifier\n",
        "# Return: output of the prediction\n",
        "def classifier_prediction(data, trained_classifier):\n",
        "  print(\"Feeded Data Shape: \" + str(data.shape))\n",
        "  pred = trained_classifier.predict(data)\n",
        "  print(\"Output Prediction Shape: \" + str(pred.shape))\n",
        "  return pred\n",
        "\n",
        "# show the accuracy of two data set, one should be label and another one is the prediction\n",
        "# Simply print the result\n",
        "def output_validation(pred_data, labels):\n",
        "  # can be replaced by self developed accuracy function\n",
        "  accuracy = accuracy_score(labels, pred_data)\n",
        "  print(\"Acuracy: \"+ str(accuracy))\n",
        "  print(\"Confusion Matrix: \\n\" + str(confusion_matrix(labels, pred_data)))\n",
        "\n",
        "# Traditional FNN network building method\n",
        "# set the model\n",
        "def fnn_build(train_data, label_data, optimizer, loss, epoch):\n",
        "  # setting initializer\n",
        "  # initializer = tf.keras.initializers.Constant(0.)\n",
        "  # initializer = tf.keras.initializers.GlorotNormal()\n",
        "  # initializer = tf.keras.initializers.Orthogonal()\n",
        "  initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(12, activation=tf.nn.relu, kernel_initializer=initializer),\n",
        "    tf.keras.layers.Dense(24, activation=tf.nn.relu, kernel_initializer=initializer),\n",
        "    tf.keras.layers.Dense(48, activation=tf.nn.relu, kernel_initializer=initializer),\n",
        "    # tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(48, activation=tf.nn.relu, kernel_initializer=initializer),\n",
        "    tf.keras.layers.Dense(24, activation=tf.nn.relu, kernel_initializer=initializer),\n",
        "    tf.keras.layers.Dense(12, activation=tf.nn.relu, kernel_initializer=initializer),\n",
        "    tf.keras.layers.Dense(6, activation=tf.nn.relu, kernel_initializer=initializer),\n",
        "    # tf.keras.layers.Dense(1)\n",
        "    tf.keras.layers.Dense(1, activation=tf.nn.relu)\n",
        "  ])\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])\n",
        "  print(\"BUILDING NEURAL NETWORK ... \")\n",
        "  # feeding the data into the model and repeat <epoch> times\n",
        "  model.fit(train_data, label_data, epochs=epoch)\n",
        "  return model\n",
        "\n",
        "# Since the accuracy of fnn model is different, need to use evaluate function\n",
        "def fnn_validate(test_data, test_labe, classifier):\n",
        "  return classifier.evaluate(test_data, test_labe)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### testing ######\n",
        "\n",
        "# Preprocessing\n",
        "vacc = pd.read_csv(\"/content/vacc_prog_clean.csv\",  header = None)\n",
        "vacc = vacc.replace(\"?\", np.NaN)\n",
        "vacc.dropna(axis=0,inplace=True)\n",
        "vacc.info()\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "for column in vacc.columns:\n",
        "  if vacc[column].dtype == \"object\":\n",
        "    vacc[column] = le.fit_transform(vacc[column])\n",
        "# vacc = vacc.drop([11, 13], axis=1)\n",
        "ca_arr = vacc.values\n",
        "# print(str(ca_arr[ca_arr[:,2] != 0,1:11].shape))\n",
        "# ca_arr = ca_arr[ca_arr[:,2] != 0, :]\n",
        "\n",
        "# Segregate features and labels into separate variables\n",
        "ca_arr = np.delete(ca_arr, 0, axis=1)\n",
        "X = np.delete(ca_arr, 7, axis=1)\n",
        "y = ca_arr[:,7]\n",
        "# X,y = ca_arr[:,1:11] , ca_arr[:,12]\n",
        "\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "# transform data\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Example of using decision tree model\n",
        "# decision_model = decision_tree_build(X_train, y_train, criterion=\"entropy\",min_samples_split=4,max_depth=3)\n",
        "# dt_prediction = classifier_prediction(X_test, decision_model)\n",
        "# accuracy = output_validation(dt_prediction, y_test)\n",
        "# print(accuracy)\n",
        "\n",
        "# Example of using randome forest model\n",
        "# forest_model = random_forest_build(X_train, y_train, n_estimators=20, criterion=\"entropy\")\n",
        "# rf_prediction = classifier_prediction(X_test, forest_model)\n",
        "# accuracy = output_validation(rf_prediction, y_test)\n",
        "# print(accuracy)\n",
        "\n",
        "# Example of using fnn model\n",
        "fnn_model = fnn_build(X_train, y_train, optimizer=\"adam\", loss=\"mean_squared_error\", epoch=10)\n",
        "accuracy = fnn_validate(X_test, y_test, fnn_model)"
      ],
      "metadata": {
        "id": "GbcMr61YcJJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2ba059-b127-45f8-f574-e2fbcfa5a342"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 36580 entries, 1 to 36580\n",
            "Data columns (total 13 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       36580 non-null  float64\n",
            " 1   1       36580 non-null  object \n",
            " 2   2       36580 non-null  object \n",
            " 3   3       36580 non-null  object \n",
            " 4   4       36580 non-null  object \n",
            " 5   5       36580 non-null  object \n",
            " 6   6       36580 non-null  object \n",
            " 7   7       36580 non-null  object \n",
            " 8   8       36580 non-null  object \n",
            " 9   9       36580 non-null  object \n",
            " 10  10      36580 non-null  object \n",
            " 11  11      36580 non-null  object \n",
            " 12  12      36580 non-null  object \n",
            "dtypes: float64(1), object(12)\n",
            "memory usage: 3.9+ MB\n",
            "BUILDING NEURAL NETWORK ... \n",
            "Epoch 1/10\n",
            "766/766 [==============================] - 5s 5ms/step - loss: 2240992.2500 - accuracy: 0.1244\n",
            "Epoch 2/10\n",
            "766/766 [==============================] - 3s 4ms/step - loss: 1661139.1250 - accuracy: 0.1815\n",
            "Epoch 3/10\n",
            "766/766 [==============================] - 3s 5ms/step - loss: 1542999.3750 - accuracy: 0.1871\n",
            "Epoch 4/10\n",
            "766/766 [==============================] - 3s 4ms/step - loss: 1463850.5000 - accuracy: 0.2021\n",
            "Epoch 5/10\n",
            "766/766 [==============================] - 5s 6ms/step - loss: 1412744.7500 - accuracy: 0.2047\n",
            "Epoch 6/10\n",
            "766/766 [==============================] - 3s 4ms/step - loss: 1382740.2500 - accuracy: 0.2010\n",
            "Epoch 7/10\n",
            "766/766 [==============================] - 4s 5ms/step - loss: 1359319.6250 - accuracy: 0.2049\n",
            "Epoch 8/10\n",
            "766/766 [==============================] - 4s 6ms/step - loss: 1339890.2500 - accuracy: 0.2078\n",
            "Epoch 9/10\n",
            "766/766 [==============================] - 4s 5ms/step - loss: 1315762.7500 - accuracy: 0.2079\n",
            "Epoch 10/10\n",
            "766/766 [==============================] - 4s 5ms/step - loss: 1299027.8750 - accuracy: 0.2107\n",
            "378/378 [==============================] - 1s 1ms/step - loss: 1311680.0000 - accuracy: 0.2227\n"
          ]
        }
      ]
    }
  ]
}